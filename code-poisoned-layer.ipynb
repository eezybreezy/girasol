{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a236f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f0fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    # ctx is the first argument to forward\n",
    "    def forward(ctx, input, weight, bias=None):\n",
    "        # The forward pass can use ctx.\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        print(f'baclward: ', input)\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output.mm(weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output.t().mm(input)\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "#         pdb.set_trace()\n",
    "        grad_weight[:input.shape[0]] = input\n",
    "        print(f'grad_weight: ', grad_weight)\n",
    "        return grad_input, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "\n",
    "class malLinear(nn.Module):\n",
    "    def __init__(self, input_features, output_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.weight = nn.Parameter(torch.empty(output_features, input_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        nn.init.uniform_(self.weight, -0.1, 0.1)\n",
    "        if self.bias is not None:\n",
    "            nn.init.uniform_(self.bias, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return LinearFunction.apply(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'input_features={}, output_features={}, bias={}'.format(\n",
    "            self.input_features, self.output_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf75ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet for CIFAR code from \n",
    "    ` https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py`\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, cifar:bool=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        if cifar:\n",
    "          self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        else:\n",
    "          self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if cifar:\n",
    "          self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        else:\n",
    "          self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n",
    "        \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = malLinear(512*block.expansion, 10)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)    \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        print(f'forward:  {out}')\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e4bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(**kwargs):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0e8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ResNet18(num_classes=4, cifar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b669682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_imgnet(path:str, size:int=224):\n",
    "    img = Image.open(path)\n",
    "    p = transforms.Compose([transforms.Resize((size, size), Image.BICUBIC)])\n",
    "    img = np.array(p(img))\n",
    "    img = img.transpose(2,0,1).reshape(1,3,224,224)\n",
    "    print(f'loaded image w/ shape {img.shape}')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_image_imgnet('data/building.jpg')\n",
    "x.shape, type(x)\n",
    "x_t = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0762d848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = torch.cat((x_t.clone().detach(), x_t.clone().detach()), 0)\n",
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e254cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward:  tensor([[0.7111, 1.7504, 0.4832,  ..., 0.0518, 0.0000, 0.8694],\n",
      "        [0.7111, 1.7504, 0.4832,  ..., 0.0518, 0.0000, 0.8694]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5440,  3.1191, -2.9588,  0.8289,  0.6569, -1.8108,  2.8210, -0.1291,\n",
       "          1.9475,  2.5500],\n",
       "        [-2.5440,  3.1191, -2.9588,  0.8289,  0.6569, -1.8108,  2.8210, -0.1291,\n",
       "          1.9475,  2.5500]], grad_fn=<LinearFunctionBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = m(x_t)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54bb6314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baclward:  tensor([[0.7111, 1.7504, 0.4832,  ..., 0.0518, 0.0000, 0.8694],\n",
      "        [0.7111, 1.7504, 0.4832,  ..., 0.0518, 0.0000, 0.8694]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "grad_weight:  tensor([[ 7.1113e-01,  1.7504e+00,  4.8317e-01,  ...,  5.1783e-02,\n",
      "          0.0000e+00,  8.6944e-01],\n",
      "        [ 7.1113e-01,  1.7504e+00,  4.8317e-01,  ...,  5.1783e-02,\n",
      "          0.0000e+00,  8.6944e-01],\n",
      "        [-4.2082e-01, -1.0358e+00, -2.8592e-01,  ..., -3.0643e-02,\n",
      "          0.0000e+00, -5.1450e-01],\n",
      "        ...,\n",
      "        [-1.8361e-02, -4.5194e-02, -1.2475e-02,  ..., -1.3370e-03,\n",
      "          0.0000e+00, -2.2448e-02],\n",
      "        [ 2.7699e-01,  6.8178e-01,  1.8820e-01,  ...,  2.0170e-02,\n",
      "          0.0000e+00,  3.3865e-01],\n",
      "        [ 3.6267e-01,  8.9268e-01,  2.4641e-01,  ...,  2.6409e-02,\n",
      "          0.0000e+00,  4.4340e-01]])\n"
     ]
    }
   ],
   "source": [
    "l = nn.MSELoss()\n",
    "b = l(c, torch.zeros(c.shape))\n",
    "b.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4aa111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m.linear.weight.grad[1] == m.linear.weight.grad[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f442b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
